{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9NzRbQv77cc"
      },
      "source": [
        "# RAG BASED Chat with PDF Application\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIEGTnQa8Kmz"
      },
      "source": [
        "### Installing necessary libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC7z4zYpEqqF",
        "outputId": "ec5d7683-bcd3-4e8f-a05d-11991734db54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.10-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.2.16-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting openai\n",
            "  Downloading openai-1.45.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.16-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyPDF4\n",
            "  Downloading PyPDF4-1.27.0.tar.gz (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.5.5-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.24-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting PyMuPDFb==1.24.10 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.24.10-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.34)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.38 (from langchain)\n",
            "  Downloading langchain_core-0.2.39-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.120-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.4.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.1)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.2)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.114.1-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.6.5-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.64.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.12.5)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting orjson>=3.9.12 (from chromadb)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.38.5-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.38->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.2)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.65.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (71.0.4)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.23.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.5.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.24.6)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (13.8.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-13.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.20.1)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.16.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n",
            "Downloading PyMuPDF-1.24.10-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMuPDFb-1.24.10-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.2.16-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.45.0-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.1/374.1 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading langchain_community-0.2.16-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-0.5.5-py3-none-any.whl (584 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.3/584.3 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.1.24-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.6/51.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading fastapi-0.114.1-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.39-py3-none-any.whl (396 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.6/396.6 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.120-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.8/289.8 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n",
            "Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.6.5-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading starlette-0.38.5-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-13.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: PyPDF4, pypika\n",
            "  Building wheel for PyPDF4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyPDF4: filename=PyPDF4-1.27.0-py3-none-any.whl size=61227 sha256=7456d7bc4ffd41ef22c99c0c0d450a9a4f47d2015e0aab3800570c977d3947cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/cc/14/cb307e5c99235c4497c7895cdb60b4f7ba2a738b6a5fc0d423\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53726 sha256=a63890972aaae9913f928c39a845b60f50a23e3bbaed7478a10fd466f5b6fd98\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built PyPDF4 pypika\n",
            "Installing collected packages: pypika, PyPDF4, monotonic, mmh3, websockets, uvloop, tenacity, python-dotenv, pypdfium2, PyMuPDFb, overrides, orjson, opentelemetry-util-http, opentelemetry-proto, mypy-extensions, marshmallow, jsonpointer, jiter, humanfriendly, httptools, h11, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, PyMuPDF, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, jsonpatch, httpcore, coloredlogs, pdfminer.six, opentelemetry-semantic-conventions, opentelemetry-instrumentation, onnxruntime, kubernetes, httpx, fastapi, dataclasses-json, pdfplumber, opentelemetry-sdk, opentelemetry-instrumentation-asgi, openai, langsmith, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, langchain-core, langchain-text-splitters, langchain_openai, chromadb, langchain, langchain_community\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed PyMuPDF-1.24.10 PyMuPDFb-1.24.10 PyPDF4-1.27.0 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 chroma-hnswlib-0.7.6 chromadb-0.5.5 coloredlogs-15.0.1 dataclasses-json-0.6.7 deprecated-1.2.14 fastapi-0.114.1 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.2 humanfriendly-10.0 jiter-0.5.0 jsonpatch-1.33 jsonpointer-3.0.0 kubernetes-30.1.0 langchain-0.2.16 langchain-core-0.2.39 langchain-text-splitters-0.2.4 langchain_community-0.2.16 langchain_openai-0.1.24 langsmith-0.1.120 marshmallow-3.22.0 mmh3-4.1.0 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.19.2 openai-1.45.0 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 orjson-3.10.7 overrides-7.7.0 pdfminer.six-20231228 pdfplumber-0.11.4 posthog-3.6.5 pypdfium2-4.30.0 pypika-0.48.9 python-dotenv-1.0.1 starlette-0.38.5 tenacity-8.5.0 tiktoken-0.7.0 typing-inspect-0.9.0 uvicorn-0.30.6 uvloop-0.20.0 watchfiles-0.24.0 websockets-13.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install PyMuPDF langchain openai python-dotenv langchain_community pdfplumber PyPDF4 chromadb langchain_openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hyanxUa8URX"
      },
      "source": [
        "#### A class to extract text from the PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7xYy3z57Emmv"
      },
      "outputs": [],
      "source": [
        "\n",
        "import fitz\n",
        "import os\n",
        "class PDFtoText():\n",
        "    def __init__(self) -> None:\n",
        "        pass\n",
        "\n",
        "    def open_pdf(self, pdf):\n",
        "        if os.path.exists(str(pdf)) or isinstance(pdf,bytes):\n",
        "                self.pdf = fitz.open(pdf)\n",
        "                self.page_count = self.pdf.page_count\n",
        "                return self.pdf\n",
        "                # self.pdf.close()\n",
        "        else:\n",
        "            raise ValueError(f\"PDF path is incorrect\", pdf)\n",
        "    def extract_all_text(self, pdf):\n",
        "         # Open the PDF file\n",
        "        if not pdf: return None\n",
        "        self.pdf = self.open_pdf(pdf)\n",
        "\n",
        "        all_text = ''\n",
        "\n",
        "        # Iterate through all pages\n",
        "        for page_number in range(self.page_count) :\n",
        "            # Get the page\n",
        "            page = self.pdf[page_number]\n",
        "\n",
        "            # Extract text from the page\n",
        "            text = page.get_text()\n",
        "            all_text += text\n",
        "\n",
        "            # Print or process the extracted text as needed\n",
        "            # print(f\"Page {page_number + 1}:\\n{text}\\n\")\n",
        "        return all_text\n",
        "\n",
        "    def extract_all_text_page_wise(self, pdf):\n",
        "         # Open the PDF file\n",
        "        if not pdf: return None\n",
        "        self.pdf = self.open_pdf(pdf)\n",
        "\n",
        "        all_text = []\n",
        "\n",
        "        # Iterate through all pages\n",
        "        for page_number in range(self.page_count) :\n",
        "            # Get the page\n",
        "            page = self.pdf[page_number]\n",
        "\n",
        "            # Extract text from the page\n",
        "            text = page.get_text()\n",
        "            all_text.append(text)\n",
        "        return all_text\n",
        "    def extract_text_from_single_page(self,pdf, page_number):\n",
        "        if not pdf: return None\n",
        "        self.pdf = self.open_pdf(pdf)\n",
        "        if page_number -1> self.page_count:\n",
        "             raise ValueError(\"Invlaid pagenumber\")\n",
        "        else:\n",
        "             return self.pdf[page_number-1].get_text()\n",
        "    def extract_text_from_interval(self,pdf,page_number, interval =1):\n",
        "        if not pdf: return None\n",
        "        self.pdf = self.open_pdf(pdf)\n",
        "        text = \"\"\n",
        "        if page_number > self.page_count:\n",
        "            raise ValueError(\"Invlaid pagenumber\")\n",
        "        else:\n",
        "            # Calculate the start and end pages\n",
        "            start_page = max(0, page_number - interval)\n",
        "            end_page = min(self.page_count - 1, page_number + interval)\n",
        "\n",
        "            for page_number in range(start_page, end_page + 1):\n",
        "                text += self.extract_text_from_single_page(pdf=pdf, page_number=page_number)\n",
        "        return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTfS1H4R8d4p"
      },
      "source": [
        "### Embedding Generation using DeepInfra Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lZKuHZtGMrQ",
        "outputId": "ac6c6f74-346d-4484-fe75-dc9ca8bce03a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "1024\n",
            "[0.016627227887511253, -0.013372370973229408, 0.0024965356569737196, 0.013677443377673626, 0.0020093938801437616, -0.03882081061601639, -0.0209063533693552, 0.04022735357284546, 0.01106675248593092, 0.033761464059352875, 0.025660647079348564, 0.0024868266191333532, -0.007759809959679842, 0.002239795168861747, -0.01601104810833931, 0.029302580282092094, -0.004804798401892185, -6.935988494660705e-05, -0.01914072223007679, 0.011064722202718258, -0.011854090727865696, 0.017241131514310837, -0.09745549410581589, -0.00010348513751523569, -0.03538932278752327, 0.041715819388628006, -0.021112671121954918, 0.00295909377746284, 0.0674673542380333, 0.029219962656497955, 0.0016559945652261376, -0.040265440940856934, 0.02257353439927101, -0.033009808510541916, -0.001523511717095971, -0.03798763081431389, 0.040762387216091156, -0.012441975995898247, 0.017350010573863983, -0.03681422397494316, 0.009441711939871311, -0.027741312980651855, 0.03842281550168991, -0.020189974457025528, -0.04473603144288063, 0.005246694199740887, -0.0022990875877439976, -0.025289999321103096, -0.03072093240916729, -0.03914408013224602, -0.055681146681308746, 0.004049432463943958, 0.011507784016430378, -0.01729724556207657, 0.05130454897880554, -0.0005641412572003901, 0.02302442118525505, 0.006752216722816229, -0.02153453230857849, 0.028722140938043594, 0.018701309338212013, 0.03203390911221504, 0.03064030408859253, -0.08543409407138824, 0.0070640514604747295, 0.030476294457912445, 0.011754602193832397, 0.0003656508051790297, 0.005939989350736141, -0.0018967213109135628, -0.017553875222802162, -0.03169950470328331, -0.04444742947816849, 0.0054418607614934444, -0.029843004420399666, 0.019059954211115837, -0.010745663195848465, -0.0036483523435890675, 0.009066845290362835, 0.045124351978302, -0.023378917947411537, -0.010083653032779694, 0.03119373321533203, -0.0028602727688848972, -0.04161779209971428, 0.020460838451981544, 0.011349547654390335, 0.010587800294160843, 0.03543040156364441, 0.022315751761198044, 0.029210394248366356, 0.022116903215646744, -0.012541841715574265, -0.010284246876835823, -0.004033572971820831, 0.029922494664788246, -0.01183140929788351, 0.029089340940117836, -0.009553947485983372, -0.006701246369630098, 0.009162360802292824, 0.021883822977542877, 0.022934913635253906, 0.0636933296918869, -0.060522615909576416, -0.01636764593422413, 0.0430770181119442, 0.012584625743329525, -0.0016229540342465043, -0.06584309041500092, -0.00484859012067318, 0.029101280495524406, 0.01542266458272934, 0.046906232833862305, 0.014585575088858604, 0.04269663244485855, -0.007880499586462975, 0.014635267667472363, -0.03133232891559601, -0.005317722912877798, -0.026451000943779945, 0.0016968202544376254, 0.030412323772907257, -0.03419926390051842, 0.033327680081129074, 0.009416746906936169, 0.0006548105739057064, 0.009312729351222515, -0.014548511244356632, 0.01780395396053791, -0.0012730899034067988, -0.004884197376668453, 0.06100010871887207, 0.0407857820391655, 0.021587183699011803, 0.007793578319251537, -0.0179592277854681, 0.013476305641233921, 0.02515879087150097, -0.01408369094133377, 0.01209151279181242, 0.04843122512102127, 0.013342569582164288, 0.06882049888372421, 0.000174935077666305, 0.052600979804992676, -0.021568210795521736, 0.01045217178761959, -0.033246226608753204, -0.0037117290776222944, -0.0366344079375267, -0.004455506335943937, -0.004449996631592512, 0.022796163335442543, -0.0126081807538867, 0.04938006028532982, -0.033709559589624405, 0.027870725840330124, 0.03038308210670948, -0.0364847369492054, -0.017167046666145325, -0.001748523791320622, -0.01570301689207554, 0.04569872468709946, -0.03740712255239487, 0.057747870683670044, -0.04967229440808296, -0.011404930613934994, 0.015374046750366688, -0.032730307430028915, 0.06999330967664719, 0.016640670597553253, -0.0542219802737236, 0.007585431914776564, 0.018917791545391083, 0.02957735024392605, 0.016193993389606476, -0.006303240079432726, 0.049279361963272095, 0.0304158553481102, -0.020292609930038452, 0.016905920580029488, 0.0455203503370285, 0.05181489512324333, 0.013471575453877449, -0.011457094922661781, 0.011378764174878597, -0.023696566000580788, -0.02334015816450119, -0.03775488957762718, -0.0030642428901046515, 0.06560627371072769, -0.0362456776201725, 0.02492624521255493, -0.013298350386321545, -0.014202573336660862, -0.05396878719329834, -0.026738004758954048, -0.0015260938089340925, -0.0785372257232666, -0.01617041975259781, 0.03896303102374077, -0.019644901156425476, 0.03676373139023781, -0.016839712858200073, -0.02748902142047882, 0.04903504624962807, 0.05015062913298607, 0.001042165793478489, -0.0031357090920209885, -0.004521508235484362, 0.015635063871741295, -0.0073568993248045444, -0.004200705327093601, 0.028874611482024193, -0.006782422307878733, 0.02390117570757866, 0.061417002230882645, -0.007247363217175007, 0.029100527986884117, 0.017528068274259567, -0.016435641795396805, 0.022477304562926292, 0.050183553248643875, 0.014182530343532562, -0.016235176473855972, 0.014250879175961018, 0.03447820246219635, 0.0033430024050176144, 0.009135592728853226, -0.022586604580283165, 0.0195343978703022, 0.01352088525891304, 0.04509197175502777, 0.052514076232910156, -0.013472956605255604, 0.04775557294487953, 0.008785051293671131, -0.010699432343244553, -0.0027323865797370672, 0.02002803608775139, 0.01765425316989422, 0.0482623428106308, 0.005393186118453741, -0.04650833457708359, 0.02316254749894142, 0.015109019353985786, 0.008518127724528313, -0.06410594284534454, 0.03268420323729515, -0.0018488194327801466, 0.0006423933082260191, 0.039132148027420044, 0.01266478281468153, -0.053464747965335846, 0.0054708207026124, 0.012142075225710869, 0.04690750315785408, -0.04798976704478264, -0.0437820702791214, -0.002867328003048897, 0.026935020461678505, 0.008653732016682625, 0.024698499590158463, 0.006651069037616253, 0.021523064002394676, -0.01511332392692566, 0.032007403671741486, 0.020930718630552292, -0.018971450626850128, -0.04211781546473503, -0.0022129833232611418, -0.06182882562279701, -0.025733372196555138, -0.04453704133629799, -0.043277330696582794, 0.020418306812644005, -0.012930228374898434, 0.037460003048181534, -0.007258906960487366, -0.0091038653627038, 0.010825198143720627, -0.028789451345801353, 0.027133919298648834, 0.027977004647254944, 0.02779320999979973, -0.02851163223385811, 0.01401575282216072, 0.04027886316180229, 0.037941303104162216, -0.011870700865983963, -0.023313110694289207, -0.011327888816595078, -0.00034967786632478237, 0.006916068959981203, -0.02131359837949276, -0.0003481340827420354, -0.013755395077168941, -0.019892841577529907, -0.03217210993170738, 0.012479467317461967, 0.014670273289084435, -0.0347774438560009, 0.02167048677802086, -0.03132811188697815, 0.03397868201136589, -0.025877729058265686, -0.03606496751308441, 0.01598762720823288, 0.020391546189785004, -0.028483793139457703, 0.036264099180698395, 0.01786193437874317, 0.02286072075366974, -0.012267098762094975, 0.005593679379671812, 0.013725904747843742, 0.04636162519454956, -0.03325921669602394, 0.012626511976122856, -0.002538833534345031, 0.004346488509327173, -0.0003904055920429528, -0.061165690422058105, -0.011108324863016605, -0.02836599573493004, 0.029679078608751297, -0.07586105167865753, 0.01933487504720688, -0.06524740904569626, -0.03434346616268158, 0.01863284409046173, -0.03320815786719322, 0.03020874410867691, -0.013873690739274025, 0.010000568814575672, -0.0017947370652109385, -0.025372151285409927, 0.002632380463182926, -0.010523438453674316, 0.05516704171895981, -0.04620884358882904, -0.014988420531153679, 0.02630295604467392, 0.023487567901611328, 0.008740270510315895, -0.000689951702952385, 0.009603750891983509, -0.004308832809329033, 0.041068438440561295, -0.0022488818503916264, 0.02627241425216198, 0.0036796005442738533, -0.0026204800233244896, 0.046231452375650406, 0.017480814829468727, -0.007660724688321352, -0.01778080314397812, 0.039634909480810165, -0.043421242386102676, 0.04062333330512047, -0.019138585776090622, 0.004247590899467468, -0.01685863360762596, -0.011910413391888142, -0.06550940126180649, 0.026616081595420837, 0.014658541418612003, 0.024729281663894653, -0.06102452427148819, 0.08546960353851318, -0.001357761211693287, -0.022406719624996185, 0.015351314097642899, -0.02806290052831173, 0.0412624217569828, 0.04038150608539581, 0.024694254621863365, 0.019317826256155968, -0.040401916950941086, 0.018926845863461494, -0.010941162705421448, 0.05499289184808731, 0.033627793192863464, 0.014002129435539246, 0.03927824646234512, -0.045282840728759766, 0.017211567610502243, -0.02208537422120571, -0.027229782193899155, -0.01781882904469967, -0.02244591899216175, 0.019917616620659828, -0.016087112948298454, -0.024071205407381058, -0.059616781771183014, 0.02158151939511299, 0.054688919335603714, 0.0229756198823452, 0.006403204053640366, 0.07328305393457413, -0.02553550712764263, -0.004179529845714569, 0.036922939121723175, -0.0024835297372192144, -0.01917937770485878, -0.026218844577670097, 0.05379195138812065, -0.0062890914268791676, -0.006496348883956671, -0.04930040240287781, -0.0027598594315350056, -0.009606082923710346, 0.03147341310977936, -0.018242357298731804, 0.014184179715812206, -0.006168167572468519, -0.006050602067261934, 0.005761133041232824, 0.00916545744985342, -0.01831790991127491, -0.006804124917834997, -0.025425974279642105, 0.05045761540532112, -0.0143210981041193, -0.06433255225419998, 0.019324133172631264, -0.031240440905094147, 0.01452880073338747, 0.021947095170617104, -0.016228139400482178, -0.01137277390807867, -0.024254469200968742, -0.01735488884150982, -0.036670856177806854, -0.032383427023887634, 0.023279063403606415, -0.008536899462342262, 0.026329325512051582, -0.059081319719552994, 0.0412084236741066, 0.0013464383082464337, 0.009076888673007488, 0.001554205548018217, -0.021227898076176643, 0.027674036100506783, 0.013911261223256588, 0.07355541735887527, -0.025752972811460495, -0.013433005660772324, -0.003958663437515497, -0.056678224354982376, 0.016377342864871025, 0.0044874874874949455, 0.00884663313627243, -0.0350293330848217, -0.001345461467280984, -0.018156833946704865, -0.006400450598448515, -0.033694490790367126, -0.033589351922273636, -0.01969568058848381, 0.0463944636285305, 9.786539158085361e-05, -0.037796903401613235, 0.0401826836168766, -0.03510157763957977, -0.02021457999944687, 0.026726149022579193, 0.02503507398068905, 0.01754196360707283, 0.014026720076799393, 0.025089217349886894, -0.012621520087122917, 0.028658783063292503, -0.008935961872339249, 0.004550441168248653, -0.001092632650397718, -0.06206571310758591, 0.038277387619018555, -0.01377082895487547, 0.017547300085425377, -0.012349954806268215, -0.010201364755630493, -0.04646885022521019, -0.06586262583732605, -0.03893181309103966, 0.05973135307431221, 0.0032464182004332542, 0.015572061762213707, -0.006194883957505226, 0.013966697268188, 0.02634870819747448, -0.04596104472875595, 0.0013808015501126647, -0.012970690615475178, -0.009214324876666069, -0.009132493287324905, -0.022792359814047813, 0.04225151240825653, 0.017944445833563805, -0.015231567434966564, -0.06949767470359802, 0.011708082631230354, -0.029453199356794357, -0.016608333215117455, -0.04431464523077011, -0.03979536145925522, -0.03124069608747959, -0.014368783682584763, -0.030051985755562782, 0.007942277938127518, -0.0038287879433482885, -0.02796047553420067, 0.013001839630305767, -0.012956150807440281, -0.024240873754024506, 0.014293244108557701, -0.029955683276057243, 0.028135180473327637, 0.0019405902130529284, -0.021863402798771858, -0.028991669416427612, 0.04695899412035942, -0.005584558937698603, 0.019258560612797737, 0.010706153698265553, -0.015537666156888008, -0.01635967195034027, -0.045598920434713364, -0.0188792385160923, -0.03519647568464279, -0.032424814999103546, -0.004281833302229643, -0.026202384382486343, 0.0037453901022672653, 0.040366947650909424, 0.031126683577895164, -0.018289340659976006, 0.011966988444328308, -0.07743202149868011, 0.027622545138001442, -0.060951489955186844, -0.018267806619405746, 0.04490123316645622, -0.04458029195666313, 0.012211105786263943, 0.06350349634885788, -0.0030071598012000322, -0.0098732216283679, 0.007851994596421719, 0.02389477752149105, -0.013960926793515682, 0.00964275747537613, -0.003924158867448568, -0.013591118156909943, 0.0025860818568617105, -0.013794831931591034, 0.018729861825704575, -0.007632131222635508, -0.036921821534633636, 0.030920032411813736, -0.021046025678515434, -0.011481347493827343, -0.0009242055821232498, -0.04080067202448845, -0.019283868372440338, -0.029179086908698082, 0.04070468619465828, -0.023248234763741493, 0.016080398112535477, -0.012554345652461052, 0.028918154537677765, 0.025059152394533157, 0.0339750312268734, -0.00041691891965456307, -0.041982389986515045, -0.08090417087078094, -0.0596516877412796, 0.007552048657089472, -0.003511493792757392, 0.015163073316216469, -0.019954657182097435, -0.009228457696735859, 0.030631842091679573, -0.014638526365160942, 0.056270431727170944, 0.06213902682065964, -0.0332527682185173, -0.004636975470930338, -0.01909789629280567, 0.012120254337787628, 0.048998769372701645, 0.012997652404010296, 0.02443171665072441, -0.00847370270639658, -0.021353118121623993, -0.00025927688693627715, -0.056644149124622345, -0.0042588235810399055, -0.04300636053085327, -0.016289887949824333, 0.05221324786543846, -0.005797744728624821, 0.026569604873657227, -0.005426938645541668, -0.0337931327521801, -0.046478837728500366, 0.06166593357920647, 0.03727814927697182, 0.00424633314833045, 0.05533790588378906, 0.001440976862795651, -0.011675429530441761, 0.06265085190534592, 0.014440277591347694, -0.023197930306196213, 0.013044163584709167, 0.04802882298827171, -0.04020215943455696, -0.020818637683987617, 0.027570411562919617, 0.032953839749097824, -0.09200889617204666, -0.005534071940928698, -0.024684365838766098, -0.022534610703587532, -0.014649204909801483, -0.0748133435845375, -0.002158390125259757, -0.051198773086071014, -0.03022640012204647, 0.01102408766746521, 0.0185635294765234, 0.006238061003386974, 0.03962484747171402, 0.0019274518126621842, 0.04114885255694389, -0.043896812945604324, -0.002710009226575494, 0.03627829998731613, -0.06378329545259476, -0.02401556633412838, -0.031229915097355843, 0.0008070704061537981, 0.014930821023881435, 0.020333386957645416, 0.02590128965675831, -0.0015184605726972222, 0.009032979607582092, 0.03626699000597, -0.02199537679553032, 0.0376010462641716, -0.05268518254160881, -0.04046117514371872, 0.02474844641983509, 0.00563492625951767, -0.04766036942601204, -0.0477687306702137, 0.009726631455123425, 0.02039388008415699, 0.06638455390930176, -0.04818267375230789, -0.012041635811328888, -0.0015907281776890159, 0.007364462595432997, -0.006444945465773344, -0.005127697251737118, -0.038419079035520554, -0.02392568439245224, -0.03395283967256546, -0.029779981821775436, -0.03966420516371727, -0.01520884595811367, 0.02409539744257927, -0.0035485844127833843, -0.020627999678254128, -0.004149142187088728, 0.0021076230332255363, 0.014555021189153194, 0.026126442477107048, -0.002288968302309513, 0.050253577530384064, -0.052965786308050156, -0.07835135608911514, -0.052186183631420135, 0.006467532366514206, -0.030928419902920723, -0.009901570156216621, -0.02483351156115532, 0.04091676324605942, -0.016995221376419067, 0.04361145943403244, 0.007672088220715523, 0.009325157850980759, -0.026469379663467407, -0.018254440277814865, 0.01671471819281578, 0.02114534191787243, -0.010457392781972885, 0.024749331176280975, 0.04144451022148132, -0.012174791656434536, -0.009570879861712456, -0.02845080941915512, 0.0064247059635818005, -0.040466081351041794, -0.04139120504260063, -0.021504979580640793, 0.0024040204007178545, -0.03298079967498779, -0.07166606932878494, -0.004085608292371035, -0.025635525584220886, 0.022803619503974915, -0.0182570181787014, -0.029316626489162445, -0.01804012432694435, -0.023609651252627373, 0.037641678005456924, 0.00784876849502325, -0.010566819459199905, 0.016445467248558998, 0.001540107186883688, 0.013663193210959435, -0.014197597280144691, 0.017121676355600357, -0.005198237020522356, -0.004178090952336788, 0.013234860263764858, -0.01957753859460354, -0.02282448299229145, 0.046018656343221664, 0.013380358926951885, 0.061556581407785416, 0.004834579303860664, -0.021795175969600677, -0.06417626887559891, -0.014621333219110966, -0.013864691369235516, 0.03216376155614853, 0.06781348586082458, 0.014621038921177387, 0.03132891282439232, -0.030874602496623993, -0.058817483484745026, 0.003919967915862799, -0.07770822942256927, -0.006776126567274332, 0.016831394284963608, -0.0018032672815024853, -0.006042375694960356, 0.03602305427193642, -0.06736020743846893, 0.021765315905213356, 0.0013294387608766556, 0.008450974710285664, 0.026795778423547745, -0.007656908128410578, 0.0008902165573090315, 0.019594743847846985, -0.0031788658816367388, 0.001717781531624496, -0.008422372862696648, 0.06202142685651779, -0.033546458929777145, -0.07225499302148819, 0.0394006073474884, -0.02294064685702324, -0.01857686974108219, 0.01087023876607418, -0.0058502922765910625, 0.013036292046308517, -0.040482185781002045, 0.00151830876711756, 0.010040356777608395, -0.016496015712618828, -0.0005691443220712245, -0.010526561178267002, -0.020313089713454247, 0.0329182967543602, -0.02569885551929474, 0.017140604555606842, -0.008136998862028122, -0.07611561566591263, -0.017227090895175934, 0.024000070989131927, 0.03782270476222038, 0.0339508131146431, 0.034369587898254395, 0.021880077198147774, -0.0034458027221262455, -0.023809460923075676, -0.04175891354680061, 0.01487780548632145, 0.0561346635222435, 0.03464909642934799, 0.03543463349342346, 0.030954966321587563, 0.009125567972660065, 0.020309867337346077, -0.017526544630527496, -0.02506365068256855, 0.01934964396059513, 0.020875565707683563, -0.02398357167840004, -0.026656368747353554, -0.07554949820041656, 0.041712455451488495, -0.005050044506788254, -0.002509569050744176, 0.008525158278644085, -0.018281370401382446, 0.0389263816177845, -0.023900622501969337, 0.021426977589726448, 0.060305479913949966, -0.04616827890276909, 0.011678751558065414, -0.009456610307097435, 0.00034048393717966974, -0.03971944749355316, 0.04071041941642761, 0.018907153978943825, 0.007193927187472582, 0.024232327938079834, 0.03111981600522995, -0.007074800319969654, 0.02502407878637314, -0.024635354056954384, 0.009965220466256142, -0.03721402958035469, -0.013639389537274837, 0.01492935512214899, -0.0036829551681876183, -0.019730575382709503, -0.032875094562768936, -0.06349621713161469, 0.018329033628106117, -0.037314895540475845, -0.009135455824434757, 0.005909577943384647, -0.05631181225180626, -0.012505668215453625, -0.036114972084760666, 0.046990249305963516, -0.002273165388032794, 0.0027697139885276556, 0.026021065190434456, 0.0033500592689961195, 0.02168099582195282, 0.0536821223795414, -0.005993834231048822, 0.023579074069857597, -0.01244718860834837, 0.05845976248383522, -0.012291324324905872, 0.058773551136255264, 0.048157691955566406, -0.003190879477187991, -0.02034260891377926, 0.018051903694868088, -0.0008463988779112697, -0.03390751779079437, -0.005276380106806755, -0.018861060962080956, 0.038994114845991135, -0.0010301365982741117, -0.01172847580164671, 0.0054311989806592464, 0.008644744753837585, 0.003030824940651655, -0.028502583503723145, -0.025296680629253387, 0.009779417887330055, -0.005402213428169489, 0.022187791764736176, 0.04468643292784691, 0.045483142137527466, 0.021609563380479813, 0.01254365500062704, -0.029379159212112427, 0.006274193525314331, 0.04195577651262283, -0.036948688328266144, 0.0602959543466568, -0.024005839601159096, -0.02584398351609707, -0.03892451152205467, -0.047668978571891785, 0.018637394532561302, 0.02252163179218769, -0.030871277675032616, -0.036885734647512436, 0.007921770215034485, 0.04408244416117668, 0.005327803082764149, 0.016594944521784782, -0.03051328845322132, 0.02153908461332321, 0.03399693965911865, 0.04595246538519859, -0.057896483689546585, 0.00528250727802515, -0.0030267059337347746, 0.004345790483057499, -0.02865472435951233, 0.0027593199629336596, 0.04192831739783287, -0.03456182777881622, -0.025035610422492027, -0.018885508179664612, 0.002215276239439845, -0.022892221808433533, -0.030763354152441025, 0.0029223491437733173, 0.03848402947187424, 0.027831487357616425, -0.036380499601364136, -0.04340319707989693, -0.03701811656355858, -0.044767946004867554, 0.009145528078079224, -0.023537704721093178, 0.04382302612066269, -0.025014817714691162, 0.015192478895187378, 0.029075637459754944, -0.06484091281890869, 0.26096028089523315, 0.05958756431937218, 0.03730928897857666, -0.02867298200726509, 0.05614525079727173, 0.02474125847220421, -0.015964306890964508, 0.013070816174149513, -0.024985728785395622, -0.010064876638352871, 0.01006846223026514, -0.007748156785964966, 0.006480114068835974, 0.03773529827594757, 0.02835121937096119, 0.027673551812767982, -0.02616170421242714, -0.03267712891101837, 0.007995863445103168, -0.03559660539031029, -0.012552297674119473, -0.002231492893770337, 0.034629855304956436, 0.056008003652095795, -0.03999054431915283, 0.018776023760437965, 0.02965513989329338, -0.02150396816432476, -0.04279416427016258, -0.026413844898343086, 0.00016955684986896813, -0.05777709186077118, 0.016924545168876648, -0.03350638225674629, -0.0489080548286438, -0.002446502912789583, 0.02393915317952633, -0.0038934724871069193, 0.025962360203266144, -0.015933826565742493, -0.0443534329533577, 0.02429947257041931, 0.018027817830443382, -0.027618976309895515, -0.00027641054475679994, 0.002035000594332814, -0.02342933975160122, 0.011062455363571644, 0.01024186797440052, -0.040854282677173615, 0.0668392926454544, -0.029024384915828705, 0.03586951643228531, -0.024423621594905853, -0.0688234195113182, -0.0247501228004694, 0.040766630321741104, -0.018980756402015686, 0.009777234867215157, -0.019271625205874443, 0.019058620557188988, -0.005681451875716448, -0.009058834984898567, 0.0188031867146492, -0.038339484483003616, 0.039709582924842834, 0.04088201746344566, 0.032978858798742294, -0.015911472961306572, 0.008336605504155159, -0.03230085223913193, -0.027129417285323143, 0.0030585681088268757, 0.017959343269467354, -0.011394774541258812, 0.012080814689397812, -0.0016632798360660672, -0.011148927733302116, 0.03260252997279167, -0.028396407142281532, 0.0034794434905052185, -0.020622070878744125, 0.008967764675617218, -0.0286165252327919, -0.020789824426174164, 0.046011269092559814, -0.02844661846756935, -0.02111036889255047, -0.0019115532049909234, 0.01792221888899803, 0.025343826040625572, 0.04158928245306015, -0.02200799062848091, 0.009051806293427944, -0.010832255706191063]\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "import os\n",
        "\n",
        "class EmbeddingGenerator:\n",
        "    def __init__(self) -> None:\n",
        "        pass\n",
        "        # Create an OpenAI client with your deepinfra token and endpoint\n",
        "        self.openai = OpenAI(\n",
        "            api_key=os.getenv(\"DEEPINFRA_API_KEY\"),\n",
        "            base_url=\"https://api.deepinfra.com/v1/openai\",\n",
        "        )\n",
        "    def embed_query(self, text:str):\n",
        "        embedding = self.openai.embeddings.create(\n",
        "        model=\"BAAI/bge-large-en-v1.5\",\n",
        "        input=text,\n",
        "        encoding_format=\"float\"\n",
        "        )\n",
        "        return embedding.data[0].embedding\n",
        "    def embed_documents(self, texts:list):\n",
        "        emb = []\n",
        "        for i in range(len(texts)):\n",
        "            embedding = self.embed_query(i)\n",
        "            emb.append(embedding)\n",
        "        return emb\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    gen = EmbeddingGenerator()\n",
        "    input = [\"Prajwal\", \"loves\", \"sakshi\"]\n",
        "    embedding =  gen.embed_documents(input)\n",
        "    print(len(embedding))\n",
        "    print(len(embedding[0]))\n",
        "    print(embedding[0])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG4fzM3V8laV"
      },
      "source": [
        "### Text Cleaning and Ingestion Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jMDMxaicFHEy"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "from typing import Callable, List, Tuple, Dict\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from dotenv import load_dotenv\n",
        "import pdfplumber\n",
        "import os\n",
        "import PyPDF4\n",
        "load_dotenv()\n",
        "os.getenv(\"DEEPINFRA_API_KEY\")\n",
        "\n",
        "embeddings = EmbeddingGenerator()\n",
        "from datetime import datetime\n",
        "\n",
        "def get_date():\n",
        "# Get today's date\n",
        "    today_date = datetime.today()\n",
        "\n",
        "# Format today's date as a string\n",
        "    return today_date.strftime('%Y-%m-%d')\n",
        "\n",
        "\n",
        "def extract_metadata_from_pdf(file_path: str) -> dict:\n",
        "    with open(file_path, \"rb\") as pdf_file:\n",
        "        reader = PyPDF4.PdfFileReader(pdf_file)  # Change this line\n",
        "        if not reader.isEncrypted:\n",
        "            metadata = reader.getDocumentInfo()\n",
        "        else:\n",
        "            metadata = {\n",
        "            \"title\": \"Title\",\n",
        "            \"author\": \"Author\",\n",
        "            \"creation_date\": get_date(),\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            \"title\": metadata.get(\"/Title\", \"\").strip(),\n",
        "            \"author\": metadata.get(\"/Author\", \"\").strip(),\n",
        "            \"creation_date\": metadata.get(\"/CreationDate\", \"\").strip(),\n",
        "        }\n",
        "def extract_pages_from_pdf(file_path: str) -> List[Tuple[int, str]]:\n",
        "    \"\"\"\n",
        "    Extracts the text from each page of the PDF.\n",
        "\n",
        "    :param file_path: The path to the PDF file.\n",
        "    :return: A list of tuples containing the page number and the extracted text.\n",
        "    \"\"\"\n",
        "    if not os.path.isfile(file_path):\n",
        "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
        "\n",
        "    with pdfplumber.open(file_path) as pdf:\n",
        "        pages = []\n",
        "        for page_num, page in enumerate(pdf.pages):\n",
        "            text = page.extract_text()\n",
        "            if text.strip():  # Check if extracted text is not empty\n",
        "                pages.append((page_num + 1, text))\n",
        "    return pages\n",
        "\n",
        "\n",
        "def parse_pdf(file_path: str) -> Tuple[List[Tuple[int, str]], Dict[str, str]]:\n",
        "    \"\"\"\n",
        "    Extracts the title and text from each page of the PDF.\n",
        "\n",
        "    :param file_path: The path to the PDF file.\n",
        "    :return: A tuple containing the title and a list of tuples with page numbers and extracted text.\n",
        "    \"\"\"\n",
        "    if not os.path.isfile(file_path):\n",
        "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
        "\n",
        "    metadata = extract_metadata_from_pdf(file_path)\n",
        "    pages = extract_pages_from_pdf(file_path)\n",
        "\n",
        "    return pages, metadata\n",
        "def parse_pdf(file_path: str) -> Tuple[List[Tuple[int, str]], Dict[str, str]]:\n",
        "    \"\"\"\n",
        "    Extracts the title and text from each page of the PDF.\n",
        "\n",
        "    :param file_path: The path to the PDF file.\n",
        "    :return: A tuple containing the title and a list of tuples with page numbers and extracted text.\n",
        "    \"\"\"\n",
        "    if not os.path.isfile(file_path):\n",
        "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
        "\n",
        "    metadata = extract_metadata_from_pdf(file_path)\n",
        "    pages = extract_pages_from_pdf(file_path)\n",
        "\n",
        "    return pages, metadata\n",
        "def extract_metadata_from_dict(news_metadata):\n",
        "        if not news_metadata: return {}\n",
        "\n",
        "        return {\n",
        "            \"title\": news_metadata.get(\"title\", \"\").strip(),\n",
        "            \"author\": news_metadata.get(\"publisher\", \"\").strip(),\n",
        "            \"creation_date\": get_date()\n",
        "        }\n",
        "\n",
        "\n",
        "def merge_hyphenated_words(text: str) -> str:\n",
        "    return re.sub(r\"(\\w)-\\n(\\w)\", r\"\\1\\2\", text)\n",
        "\n",
        "\n",
        "def fix_newlines(text: str) -> str:\n",
        "    return re.sub(r\"(?<!\\n)\\n(?!\\n)\", \" \", text)\n",
        "\n",
        "\n",
        "def remove_multiple_newlines(text: str) -> str:\n",
        "    return re.sub(r\"\\n{2,}\", \"\\n\", text)\n",
        "\n",
        "def clean_text_str(text:str, cleaning_functions: List[Callable[[str], str]]):\n",
        "    for cleaning_function in cleaning_functions:\n",
        "            result = cleaning_function(text)\n",
        "\n",
        "    return result\n",
        "def clean_text(\n",
        "    pages: List[Tuple[int, str]], cleaning_functions: List[Callable[[str], str]]\n",
        ") -> List[Tuple[int, str]]:\n",
        "    cleaned_pages = []\n",
        "    for page_num, text in pages:\n",
        "        for cleaning_function in cleaning_functions:\n",
        "            text = cleaning_function(text)\n",
        "        cleaned_pages.append((page_num, text))\n",
        "    return cleaned_pages\n",
        "def text_to_docs(text: List[str], metadata: Dict[str, str]) -> List[Document]:\n",
        "    \"\"\"Converts list of strings to a list of Documents with metadata.\"\"\"\n",
        "    doc_chunks = []\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000,\n",
        "            separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
        "            chunk_overlap=200,\n",
        "        )\n",
        "    for page_num, page in text:\n",
        "        chunks = text_splitter.split_text(page)\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            doc = Document(\n",
        "                page_content=chunk,\n",
        "                metadata={\n",
        "                    \"page_number\": page_num,\n",
        "                    \"chunk\": i,\n",
        "                    \"source\": f\"p{page_num}-{i}\",\n",
        "                    **metadata,\n",
        "                },\n",
        "            )\n",
        "            doc_chunks.append(doc)\n",
        "\n",
        "    return doc_chunks\n",
        "\n",
        "def ingest_new_file(file_path, collection_name):\n",
        "    # Step 1: Parse PDF\n",
        "    raw_pages, metadata = parse_pdf(file_path)\n",
        "\n",
        "    # Step 2: Create text chunks\n",
        "    cleaning_functions = [\n",
        "        merge_hyphenated_words,\n",
        "        fix_newlines,\n",
        "        remove_multiple_newlines,\n",
        "    ]\n",
        "\n",
        "    cleaned_text_pdf = clean_text(raw_pages, cleaning_functions)\n",
        "    document_chunks = text_to_docs(cleaned_text_pdf, metadata)\n",
        "\n",
        "    # Optional: Reduce embedding cost by only using the first 23 pages\n",
        "    # document_chunks = document_chunks[:10]\n",
        "\n",
        "    # Step 3 + 4: Generate embeddings and store them in DB\n",
        "    vector_store = Chroma.from_documents(\n",
        "        document_chunks,\n",
        "        embeddings,\n",
        "        collection_name=os.getenv(\"default_collection_name\") if collection_name is None or \"\" else collection_name,\n",
        "        persist_directory=os.getenv(\"default_data_directory\")\n",
        "    )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gU6RwjJ8r0N"
      },
      "source": [
        "### The Chat model and the Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk6MNBU0ItyF",
        "outputId": "49cf820c-3f37-47a2-c542-71f3d454a300"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Samples are used in various ways in biomedical research and laboratory practices, including:\n",
            "\n",
            "1. **Biorepositories**: Samples are stored in biorepositories for future research, such as studying the genetic basis of diseases.\n",
            "2. **Disease diagnosis**: Samples are used to diagnose diseases, such as cancer, infectious diseases, and genetic disorders.\n",
            "3. **Forensic analysis**: Samples are used in forensic analysis, such as DNA profiling, to aid in crime investigations.\n",
            "4. **Population-based studies**: Samples are used to study the genetic and environmental factors that contribute to disease development in populations.\n",
            "5. **Proteomic analysis**: Samples are used to study proteins and their functions in biological systems.\n",
            "6. **Vaccine development**: Samples are used to develop and test vaccines against infectious diseases.\n",
            "7. **Toxicology testing**: Samples are used to test the toxicity of chemicals and drugs.\n",
            "8. **Genetic research**: Samples are used to study the genetic basis of diseases and to develop genetic therapies.\n",
            "9. **Cancer research**: Samples are used to study the biology of cancer and to develop cancer therapies.\n",
            "10. **Quality control**: Samples are used to ensure the quality of laboratory tests and procedures.\n",
            "\n",
            "These are just a few examples of the many ways that samples are used in biomedical research and laboratory practices. [16, 17, 19, 20]\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.schema import HumanMessage, AIMessage\n",
        "from langchain.schema.vectorstore import VectorStoreRetriever\n",
        "from langchain.callbacks.manager import CallbackManagerForRetrieverRun\n",
        "from langchain.schema.document import Document\n",
        "from typing import List\n",
        "from langchain_community.llms import DeepInfra\n",
        "from langchain.chains import LLMChain\n",
        "import math\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "import os\n",
        "load_dotenv()\n",
        "os.environ[\"DEEPINFRA_API_TOKEN\"]  = os.getenv(\"DEEPINFRA_API_KEY\")\n",
        "\n",
        "\n",
        "\n",
        "class MyVectorStoreRetriever(VectorStoreRetriever):\n",
        "    # See https://github.com/langchain-ai/langchain/blob/61dd92f8215daef3d9cf1734b0d1f8c70c1571c3/libs/langchain/langchain/vectorstores/base.py#L500\n",
        "    def _get_relevant_documents(\n",
        "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
        "    ) -> List[Document]:\n",
        "        docs_and_similarities = (\n",
        "            self.vectorstore.similarity_search_with_relevance_scores(\n",
        "                query, **self.search_kwargs\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Make the score part of the document metadata\n",
        "        for doc, similarity in docs_and_similarities:\n",
        "            doc.metadata[\"score\"] = similarity\n",
        "\n",
        "        docs = [doc for doc, _ in docs_and_similarities]\n",
        "        return docs\n",
        "\n",
        "\n",
        "\n",
        "class Chat:\n",
        "    def __init__(self, collection_name=\"\"):\n",
        "        '''\n",
        "        return ConversationalRetrievalChain.from_llm(\n",
        "            model,\n",
        "            #retriever=vector_store.as_retriever(),\n",
        "            retriever = MyVectorStoreRetriever(\n",
        "                vectorstore=vector_store,\n",
        "                search_type=\"similarity_score_threshold\",\n",
        "                search_kwargs={\"score_threshold\": 0.2, \"k\": 3},\n",
        "            ),\n",
        "            return_source_documents=True,\n",
        "            # verbose=True,\n",
        "        )\n",
        "    '''\n",
        "        self.embedding = EmbeddingGenerator()\n",
        "        self.collection_name=collection_name\n",
        "        self.vector_store = Chroma(\n",
        "            collection_name=os.getenv(\"default_collection_name\") if self.collection_name == \"\" or None else self.collection_name,\n",
        "            embedding_function=self.embedding,\n",
        "            persist_directory=os.getenv(\"default_data_directory\"),\n",
        "        )\n",
        "        self.chain = RetrievalQA.from_chain_type(\n",
        "            DeepInfra(model_id=os.getenv(\"CHAT_MODEL_NAME\")),\n",
        "            chain_type=os.getenv(\"chain_type\"),\n",
        "\n",
        "            retriever = MyVectorStoreRetriever(\n",
        "                vectorstore=self.vector_store,\n",
        "                search_type=os.getenv(\"search_type\"),\n",
        "                search_kwargs={\"score_threshold\": float(os.getenv(\"score_threshold\")), \"k\": int(os.getenv(\"top_k_to_search\"))},\n",
        "            ),\n",
        "            return_source_documents=True,\n",
        "        )\n",
        "\n",
        "    def chat(self, question, chat_history = [], collection_name=None):\n",
        "        answer = None\n",
        "        response = self.chain({\"query\": question, \"history\":chat_history})\n",
        "        answer = response[\"result\"]\n",
        "        source = response[\"source_documents\"]\n",
        "\n",
        "        pgs = []\n",
        "        for document in source:\n",
        "            pgs.append(document.metadata['page_number'])\n",
        "            #print(f\"List after inserting:\", pgs)\n",
        "\n",
        "        for i in range(0, len(pgs)):\n",
        "            for j in range(i+1, len(pgs)):\n",
        "                #if(l[i] == l[j]):\n",
        "                if(math.isclose(pgs[i], pgs[j], abs_tol = 2)):\n",
        "                        pgs.insert(0, pgs[i])\n",
        "        pgs = list(set(pgs))\n",
        "        return answer, pgs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    load_dotenv()\n",
        "    chat = Chat(collection_name=\"Praj\")\n",
        "    ingest_new_file(\"Data\\IARC Sci Pub 163_Chapter 3.pdf\", collection_name=\"Praj\")\n",
        "    chat_history = []\n",
        "    question = \"what are some usage of samples, Biomedical research and laboratory practices\"\n",
        "    answer, pgs = chat.chat(question = question, collection_name=\"Praj\", chat_history=[] )\n",
        "    chat_history.append(answer)\n",
        "    print(answer, pgs)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f5NICgB81W-"
      },
      "source": [
        "### Example Queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLSJET84JNIT"
      },
      "outputs": [],
      "source": [
        "question_1  = \"What are the freezers used for?\"\n",
        "answer_1  = \"The freezers are used for storing biological samples. [16, 1, 23]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHCP3zKMP0el"
      },
      "outputs": [],
      "source": [
        "question_2 = \"where are the samples stored\"\n",
        "answer_2  = \" According to the context, the samples are stored in liquid nitrogen freezers at -196°C, and also in dry ice, which is used as a refrigerant for shipping. [16, 11, 23, 15]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdYlL4O5Qmqb"
      },
      "outputs": [],
      "source": [
        "question_3 = \"Generally, what are the samples about\"\n",
        "answer_3 = \"\"\"\n",
        "The samples appear to be related to various topics, including:\n",
        "\n",
        "1. Biomedical research and laboratory practices (e.g., specimen collection, storage, and processing).\n",
        "2. Business and finance (e.g., revenue, expenses, and profitability).\n",
        "3. Telecommunications and technology (e.g., wireless and broadband services).\n",
        "4. Occupational safety and health regulations (e.g., OSHA guidelines).\n",
        "\n",
        "It's challenging to pinpoint a single, overarching theme, as the samples seem to cover diverse subjects. [16, 24, 19, 23]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCfVy89pQ8s6"
      },
      "outputs": [],
      "source": [
        "question_4 = \"what are some usage of samples, Biomedical research and laboratory practices\"\n",
        "answer_5 = \"\"\"\n",
        "In biomedical research and laboratory practices, samples are used for various purposes, including:\n",
        "\n",
        "1. **Disease diagnosis and monitoring**: Biological samples, such as blood, tissue, or urine, are used to diagnose and monitor diseases, including cancer, infectious diseases, and genetic disorders.\n",
        "2. **Research nd development**: Samples are used to develop new treatments, vaccines, and diagnostic tools, and to understand the underlying biology of diseases.\n",
        "3. **Quality control and assurance**: Samples are used to ensure the quality of laboratory tests, reagents, and equipment.\n",
        "4. **Toxicology and pharmacology studies**: Samples are used to study the effects of drugs, chemicals, and other substances on living organisms.\n",
        "5. **Forensic analysis**: Biological samples, such as DNA, are used in forensic science to aid in the investigation of crimes.\n",
        "6. **Population-based studies**: Samples are used to study the health and disease patterns of populations, and to identify risk factors and trends.\n",
        "7. **Biobanking**: Samples are stored in biobanks for future research, enabling the study of diseases and the development of new treatments over time.\n",
        "\n",
        "These are just a few examples of the many uses of samples in biomedical research and laboratory practices. [16, 17, 20, 23, 24]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zZAUJuxRY-W"
      },
      "outputs": [],
      "source": [
        "question_5 = \"What are the parameters under which the samples are stored?\"\n",
        "answer_5 = \"Cryoprotectants that are less toxic have been developed to allow for preservation of RNA and DNA in blood and other specimens. Whole blood may also be cryopreserved in large-scale epidemiological studies. Saliva or blood collected on treated paper cards is available for laboratory applications. Enough DNA can be obtained from a 2mm punch of a paper card for about 500 reactions. [9, 3, 12]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kv7prtcoRzLW"
      },
      "outputs": [],
      "source": [
        "question_6 = \"List down some type of specimens\"\n",
        "answer_6 = \"\"\"Based on the provided context, some types of specimens mentioned are:\n",
        "\n",
        "* Blood\n",
        "* Urine\n",
        "* Saliva\n",
        "\n",
        "Please note that these are the only types of specimens explicitly mentioned in the provided context. There may be other types of specimens not mentioned here. [3]\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6X2WbVkSHiI"
      },
      "outputs": [],
      "source": [
        "question_7 = \"List down all the types and definitions of specimen you know\"\n",
        "answer_7 = \"\"\" Here are some types and definitions of specimens:\n",
        "\n",
        "1. **Biological specimen**: A sample of tissue, blood, or other bodily fluid taken from a living organism for diagnostic, therapeutic, or research purposes.\n",
        "2. **Formalin-fixed paraffin-embedded (FFPE) specimen**: A tissue sample that has been preserved in formalin and embedded in paraffin wax to create a solid block that can be sectioned and stained for histological examination.\n",
        "3. **Frozen specimen**: A tissue or cell sample that has been frozen to preserve its molecular structure and function, often used for DNA, RNA, or protein analysis.\n",
        "4. **Fresh specimen**: A tissue or cell sample that has not been fixed or preserved, often used for immediate analysis or processing.\n",
        "5. **Cryopreserved specimen**: A tissue or cell sample that has been frozen at very low temperatures (typically -196°C) to preserve its molecular structure and function, often used for long-term storage.\n",
        "6. **Chemically fixed specimen**: A tissue or cell sample that has been treated with a chemical fixative to preserve its structure and prevent degradation, often used for histological examination.\n",
        "7. **Paraffin-embedded specimen**: A tissue sample that has been embedded in paraffin wax to create a solid block that can be sectioned and stained for histological examination.\n",
        "8. **Whole blood specimen**: A sample of whole blood collected from a patient or donor for diagnostic or therapeutic purposes.\n",
        "9. **Serum specimen**: A sample of blood serum (the liquid portion of blood) collected from a patient or donor for diagnostic or therapeutic purposes.\n",
        "10. **Urine specimen**: A sample of urine collected from a patient or donor for diagnostic or therapeutic purposes.\n",
        "11. **Tissue microarray (TMA) specimen**: A collection of tissue samples arranged in a grid pattern on a single slide, often used for high-throughput analysis of multiple tissue samples.\n",
        "12. **Cell block specimen**: A sample of cells that have been aggregated and embedded in a paraffin block, often used for histological examination.\n",
        "13. **Cytology specimen**: A sample of cells collected from a patient or donor for diagnostic purposes, often used for cytological examination.\n",
        "14. **Histology specimen**: A tissue sample that has been processed and stained for histological examination.\n",
        "15. **Molecular specimen**: A sample of tissue, blood, or other bodily fluid collected for molecular analysis, such as DNA, RNA, or protein analysis.\n",
        "\n",
        "These are just a few examples of the [24, 17, 26, 19]\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbJrJEnITlUb"
      },
      "outputs": [],
      "source": [
        "question_8 = \"What are some ways to collect urine?\"\n",
        "answer_8 = \"\"\"Here are some ways to collect urine:\n",
        "\n",
        "1. **Clean Catch Midstream Urine Collection**: This is the most common method. The patient cleans their genital area, starts urinating, and then collects a sample in a sterile container.\n",
        "2. **Catheterization**: A healthcare professional inserts a catheter into the bladder to collect a urine sample. This method is often used for patients who cannot urinate on their own or have a urinary tract infection.\n",
        "3. **Urine Bag Collection**: A sterile urine collection bag is attached to the genital area to collect urine. This method is often used for infants or young children.\n",
        "4. **Suprapubic Aspiration**: A healthcare professional uses a needle to collect a urine sample directly from the bladder. This method is often used for patients with urinary retention or bladder dysfunction.\n",
        "5. **Urinary Catheter with a Collection Bag**: A urinary catheter is inserted into the bladder, and a collection bag is attached to collect urine. This method is often used for patients who require continuous urine drainage.\n",
        "\n",
        "It's essential to follow proper techniques and guidelines when collecting urine to ensure the sample is sterile and accurate for laboratory testing. [18, 19, 13]\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
